---
title: "Page Load Analysis"
author: "tdresser@chromium.org, maxlg@chromium.org, dproy@chromium.org"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    fig_width: 12
    fig_height: 10
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
options(scipen=10000)
knitr::opts_knit$set(verbose=TRUE)
library(plotly)
library(tidyverse)
library(DT)
source ('r_helpers/r_defaults.R')
source ('r_helpers/r_helpers.R')

# source('main.R')
load(".RData.main")

```

## Gathering Data
* Load the Alexa top 10k on Nexus 5X's.
* Simulate 3G network.
* Perform cold, warm and hot page loads.
* Run with Subresource Filter enabled, and disabled.
* Gather reasonably detailed main thread attribution.

All data is measured using live sites. This is required to get ads to behave reasonably, though it introduces some variance between runs.

We've excluded pages which didn't reach Time to Interactive across all tests.

## Overall Distribution

Each point represents one run on a specific site. In this aggregate view, it's difficult to see any difference between the subresource filter being on or off. The clean, low bands seen in most graphs appear to be pages which 404 in our page set.

#### Totals per point in time.

```{r, echo=FALSE, warning=FALSE}

plot_totals_jitter +
  labs(x="Cache Temperature", y="Seconds")
```

We've included this view to make it easy to pick out sample sites which fall in various places in these distributions.

#### Totals per point in time (sampled)

```{r, echo=FALSE, warning=FALSE}
myplotly(plot_totals_jitter_sampled + labs(x="Cache temperature", y="Seconds"))
```

The x-axis here is the number of seconds taken to reach each key point in time. The y-axis is density: how common are values around this one?

Turn lines on and off by clicking on them in the legend. It's interesting that the CPU graphs are generally pretty close to unimodal (apart from a lump at the bottom we believe to be 404 pages), but the wall time graphs are strongly multimodal.

Selecting pairs which differ only between the subresource filter being on and off illustrates the difference, which is largest for Time to Interactive.

#### Distribution per stage

```{r, echo=FALSE}
totals$interaction <- interaction(totals$cache_temperature, totals$is_cpu_time, totals$subresource_filter)
plot_totals_density <- totals %>%
  ggplot(aes(value, group = interaction, color=interaction, text=interaction)) +
  geom_line(stat="density") +
  facet_grid(end ~ .) +
  scale_color_manual(values = colorRampPalette(brewer.pal(name="Set1", n = 8))(14)) +
  scale_x_log10() +
  labs(x="Seconds to reach Stage", y="Density")

myplotly(plot_totals_density)
```

#### Table for First Contentful Paint

```{r, echo=FALSE}
datatable(totals %>% 
             filter(end == "First Contentful Paint") %>% 
             group_by(cache_temperature, is_cpu_time, subresource_filter) %>% 
             summarize(mean = mean(value), 
                       percentile_90 = quantile(value, 0.9),
                       percentile_99 = quantile(value, 0.99)),
          rownames = FALSE,
          options = list(pageLength=50)) %>% 
  formatRound('mean', 2) %>%
  formatRound('percentile_90', 2) %>%
  formatRound('percentile_99', 2) 
```

```{r echo=FALSE}
fcp_plots <- get_endpoint_plots("First Contentful Paint")
```

## First Contentful Paint

In the mean, we're essentially solely blocked on resource requests.

otherNetworkActivities refers to resource requests handled on the browser side. We need to figure out if we can split these out more.

We use a hierarchy to attribute time. Of the following, we attribute time to the first activity present.

* Main thread tasks
* Main thread resource requests
* Browser side resource requests

Our CPU time is slightly higher for warm than cold loads in the mean. This is because FCP itself is later, giving more time for CPU work. TODO - this makes no sense?

From the breakdowns we do have, we can see that time spent fetching script and images dominates.

#### Time To First Contentful Paint â€” Mean Contributors

```{r echo=FALSE, warning=FALSE}
myplotly(fcp_plots$warm_vs_cold) 
```

Zooming into the CPU work shows that most time is spent executing script, and on "resource_loading". This is work the main thread does to process resources. This is a lot more work than I anticipated!

#### First Contentful Paint | Quantiles

```{r echo=FALSE, warning=FALSE}
myplotly(fcp_plots$contributors_by_quantile)
```

#### First Contentful Paint | Normalized by quantiles

The normalized data shows that the fraction of time spent per category is surprisingly consistent. Image loading is much more of an issue on the first load than subsequent loads. Pages which are slower tend to have longer running scripts. It's interesting that the time spent fetching images and script is pretty constant for cold loads, but for script especially, there's a strong correlation between FCP and time spent fetching script in cold and warm loads. 

```{r echo=FALSE, warning=FALSE}
myplotly(fcp_plots$contributors_by_quantile_normalized)
```

```{r echo=FALSE}
ci_plots <- get_endpoint_plots("Interactive")
```

## Time To Interactive

Mean contributions to Time to Interactive clearly show the impact of subresource filtering. The average time spent blocked on loading images dropped from 10.7 to 9.7 seconds. In the 90th percentile, there was a drop from 25.3 to 22.3 seconds here.

```{r echo=FALSE, warning=FALSE}
myplotly(ci_plots$warm_vs_cold)
```

## Time To Interactive | Quantiles
```{r echo=FALSE, warning=FALSE}
myplotly(ci_plots$contributors_by_quantile)
```

## Time To Interactive | Normalized by quantiles
```{r echo=FALSE, warning=FALSE}
myplotly(ci_plots$contributors_by_quantile_normalized)
```

## Important Timestamp Deltas

This shows the mean contribution per contributor per important timestamp. The first column is time from navigation start to first paint.

#### Mean Contributors between Key Timestamps

```{r echo=FALSE, warning=FALSE}
myplotly(plot_important_times)
```

## Per Second Contributors

This shows the mean contribution per contributor per important second.

#### Mean Contributors over time

```{r echo=FALSE, warning=FALSE}
#source('per_second.R')
load(".RData.per_second")
myplotly(plot_per_second)
```

Below is the mean contribution per contributor per important second, only for the worst 100 sites (measured by wall clock TTI, without the subresource filter, with a cold cache).

#### Mean Contributors over time (Worst 100 sites)

```{r echo=FALSE, warning=FALSE}
myplotly(plot_per_second_worst100)
```

#### Mean Contributors over time (Best 100 sites)

```{r echo=FALSE, warning=FALSE}
myplotly(plot_per_second_best100)
```



